{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vSlX6Eqo7Q0"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nwzkTow9owXY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 20\n",
    "    batch_size = 20\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    data = load_pkl('label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U4mioWQrrHm"
   },
   "source": [
    "如果把Epoch改成20，Batch Size改成20，可以把Accuracy提升到0.839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InUGmgMZo3J4",
    "outputId": "bf53ad75-79cb-4dcb-cda1-a4471a460d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "750/750 [==============================] - 19s 24ms/step - loss: 1.8860 - accuracy: 0.2594 - val_loss: 1.3246 - val_accuracy: 0.4098\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 1.2386 - accuracy: 0.4855 - val_loss: 0.7120 - val_accuracy: 0.7310\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.7856 - accuracy: 0.6899 - val_loss: 0.5952 - val_accuracy: 0.7726\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.6865 - accuracy: 0.7318 - val_loss: 0.5317 - val_accuracy: 0.8004\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: 0.6843 - accuracy: 0.7377 - val_loss: 0.5350 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.6190 - accuracy: 0.7634 - val_loss: 0.5095 - val_accuracy: 0.8058\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.5830 - accuracy: 0.7826 - val_loss: 0.4510 - val_accuracy: 0.8354\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: 0.5545 - accuracy: 0.7925 - val_loss: 0.4824 - val_accuracy: 0.8146\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.5225 - accuracy: 0.7995 - val_loss: 0.5636 - val_accuracy: 0.7950\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.5181 - accuracy: 0.8032 - val_loss: 0.5118 - val_accuracy: 0.8042\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.5716 - accuracy: 0.7845 - val_loss: 0.4159 - val_accuracy: 0.8508\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: 0.5057 - accuracy: 0.8117 - val_loss: 0.4291 - val_accuracy: 0.8336\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.4923 - accuracy: 0.8142 - val_loss: 0.5233 - val_accuracy: 0.7920\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.5067 - accuracy: 0.8102 - val_loss: 0.4481 - val_accuracy: 0.8360\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.5053 - accuracy: 0.8074 - val_loss: 0.5095 - val_accuracy: 0.7966\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.4833 - accuracy: 0.8162 - val_loss: 0.4444 - val_accuracy: 0.8372\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 18s 23ms/step - loss: 0.4966 - accuracy: 0.8109 - val_loss: 0.4189 - val_accuracy: 0.8422\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 17s 23ms/step - loss: 0.4718 - accuracy: 0.8231 - val_loss: 0.4815 - val_accuracy: 0.8164\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.4595 - accuracy: 0.8263 - val_loss: 0.4412 - val_accuracy: 0.8360\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.4615 - accuracy: 0.8263 - val_loss: 0.4285 - val_accuracy: 0.8392\n",
      "LSTM test accuracy: 0.8392000198364258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1762  167  129  199  105  137  241  146  114]\n",
      " [  36 1458    0    4    0    0    2    0    0]\n",
      " [ 101    0 1368    0   31    0    0    0    0]\n",
      " [   9   56    0 1410    0    0    0   25    0]\n",
      " [  75    0    6    0 1328    0    2    0   89]\n",
      " [  36    4    0   13    0 1256    3  188    0]\n",
      " [  17    2    0    0    1    0 1436    0   44]\n",
      " [   2    5    0  493    0    0    0 1000    0]\n",
      " [  30    0    1    0  207    0   29    0 1233]] \n",
      "\n",
      " [[592  53  50  61  40  43  76  50  35]\n",
      " [  3 497   0   0   0   0   0   0   0]\n",
      " [ 17   0 477   0   6   0   0   0   0]\n",
      " [  6  14   0 476   0   0   0   4   0]\n",
      " [ 29   0   4   0 440   0   0   0  27]\n",
      " [ 10   0   0   2   0 446   0  42   0]\n",
      " [  6   0   0   0   0   0 484   0  10]\n",
      " [  1   1   0 151   0   0   0 347   0]\n",
      " [  7   0   0   0  48   0   8   0 437]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TP8TyLioo6Dm"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "utHBAHfFdmKP"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggPdssx-umMx"
   },
   "source": [
    "調了Learning Rate, Epochs 以及Batch_size, 最後得到最好的結果是0.845799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWqSz3BSduFI",
    "outputId": "f18a77ea-d046-4c5d-d632-be59183078fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "375/375 - 7s - loss: 2.1400 - accuracy: 0.1806\n",
      "Epoch 2/40\n",
      "375/375 - 7s - loss: 1.9204 - accuracy: 0.2773\n",
      "Epoch 3/40\n",
      "375/375 - 7s - loss: 1.6248 - accuracy: 0.4121\n",
      "Epoch 4/40\n",
      "375/375 - 7s - loss: 1.3993 - accuracy: 0.5145\n",
      "Epoch 5/40\n",
      "375/375 - 7s - loss: 1.1936 - accuracy: 0.5974\n",
      "Epoch 6/40\n",
      "375/375 - 7s - loss: 1.0113 - accuracy: 0.6689\n",
      "Epoch 7/40\n",
      "375/375 - 7s - loss: 0.8838 - accuracy: 0.6985\n",
      "Epoch 8/40\n",
      "375/375 - 7s - loss: 0.7985 - accuracy: 0.7289\n",
      "Epoch 9/40\n",
      "375/375 - 7s - loss: 0.7385 - accuracy: 0.7445\n",
      "Epoch 10/40\n",
      "375/375 - 7s - loss: 0.6940 - accuracy: 0.7584\n",
      "Epoch 11/40\n",
      "375/375 - 7s - loss: 0.6563 - accuracy: 0.7725\n",
      "Epoch 12/40\n",
      "375/375 - 7s - loss: 0.6257 - accuracy: 0.7787\n",
      "Epoch 13/40\n",
      "375/375 - 7s - loss: 0.5995 - accuracy: 0.7903\n",
      "Epoch 14/40\n",
      "375/375 - 7s - loss: 0.5776 - accuracy: 0.7976\n",
      "Epoch 15/40\n",
      "375/375 - 7s - loss: 0.5561 - accuracy: 0.8033\n",
      "Epoch 16/40\n",
      "375/375 - 7s - loss: 0.5408 - accuracy: 0.8103\n",
      "Epoch 17/40\n",
      "375/375 - 7s - loss: 0.5263 - accuracy: 0.8158\n",
      "Epoch 18/40\n",
      "375/375 - 7s - loss: 0.5138 - accuracy: 0.8199\n",
      "Epoch 19/40\n",
      "375/375 - 7s - loss: 0.5032 - accuracy: 0.8221\n",
      "Epoch 20/40\n",
      "375/375 - 7s - loss: 0.4926 - accuracy: 0.8251\n",
      "Epoch 21/40\n",
      "375/375 - 7s - loss: 0.4847 - accuracy: 0.8283\n",
      "Epoch 22/40\n",
      "375/375 - 7s - loss: 0.4771 - accuracy: 0.8281\n",
      "Epoch 23/40\n",
      "375/375 - 7s - loss: 0.4682 - accuracy: 0.8319\n",
      "Epoch 24/40\n",
      "375/375 - 7s - loss: 0.4626 - accuracy: 0.8327\n",
      "Epoch 25/40\n",
      "375/375 - 7s - loss: 0.4565 - accuracy: 0.8339\n",
      "Epoch 26/40\n",
      "375/375 - 7s - loss: 0.4515 - accuracy: 0.8374\n",
      "Epoch 27/40\n",
      "375/375 - 7s - loss: 0.4464 - accuracy: 0.8402\n",
      "Epoch 28/40\n",
      "375/375 - 7s - loss: 0.4403 - accuracy: 0.8449\n",
      "Epoch 29/40\n",
      "375/375 - 7s - loss: 0.4364 - accuracy: 0.8447\n",
      "Epoch 30/40\n",
      "375/375 - 7s - loss: 0.4319 - accuracy: 0.8442\n",
      "Epoch 31/40\n",
      "375/375 - 7s - loss: 0.4271 - accuracy: 0.8485\n",
      "Epoch 32/40\n",
      "375/375 - 7s - loss: 0.4248 - accuracy: 0.8481\n",
      "Epoch 33/40\n",
      "375/375 - 7s - loss: 0.4191 - accuracy: 0.8501\n",
      "Epoch 34/40\n",
      "375/375 - 7s - loss: 0.4160 - accuracy: 0.8509\n",
      "Epoch 35/40\n",
      "375/375 - 7s - loss: 0.4124 - accuracy: 0.8533\n",
      "Epoch 36/40\n",
      "375/375 - 7s - loss: 0.4092 - accuracy: 0.8528\n",
      "Epoch 37/40\n",
      "375/375 - 7s - loss: 0.4059 - accuracy: 0.8557\n",
      "Epoch 38/40\n",
      "375/375 - 7s - loss: 0.4036 - accuracy: 0.8572\n",
      "Epoch 39/40\n",
      "375/375 - 7s - loss: 0.4013 - accuracy: 0.8556\n",
      "Epoch 40/40\n",
      "375/375 - 7s - loss: 0.3975 - accuracy: 0.8587\n",
      "CNN test accuracy: 0.84579998254776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2359   67  105   98   53   60  114   68   76]\n",
      " [  82 1408    0    9    0    0    1    0    0]\n",
      " [  85    0 1407    0    8    0    0    0    0]\n",
      " [  74   32    0 1323    0    0    0   71    0]\n",
      " [ 105    0   28    0 1012    0    7    0  348]\n",
      " [ 172    0    0    2    0 1296    2   28    0]\n",
      " [  82    2    2    0    0    0 1378    0   36]\n",
      " [  73    3    0  184    0    8    0 1232    0]\n",
      " [  67    0    2    0   60    0   55    0 1316]] \n",
      "\n",
      " [[782  22  43  32  20  20  26  25  30]\n",
      " [ 18 478   0   4   0   0   0   0   0]\n",
      " [ 26   0 474   0   0   0   0   0   0]\n",
      " [ 37  10   0 438   0   0   0  15   0]\n",
      " [ 59   0   9   0 319   0   1   0 112]\n",
      " [ 74   0   0   0   0 420   0   6   0]\n",
      " [ 40   0   1   0   0   0 454   0   5]\n",
      " [ 29   1   0  43   0   3   0 424   0]\n",
      " [ 37   0   0   0   4   0  19   0 440]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['pkl_name'] = 'label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.001\n",
    "PARAMS['epochs'] = 40\n",
    "PARAMS['batch_size'] = 40\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s_vfB4VmEp9"
   },
   "source": [
    "# Reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Peculab Github](https://github.com/pecu/FinTech_CommonWealth_Magazine/tree/master/Financial_Innovation/FiancailVision/HW2_ID_%E5%A7%93%E5%90%8D)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW3_r08723029_黃世漳.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
